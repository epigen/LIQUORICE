

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>liquorice.utils.BiasModel &mdash; LIQUORICE 0.5.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/liquorice_logo_fitted_transparent.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html#citation">Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../liquorice.html">The <cite>liquorice</cite> python package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../liquorice_commandline_tool.html">The LIQUORICE command-line-tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../liquorice_commandline_tool.html#liquorice-s-summary-tool">LIQUORICEâ€™s summary tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../liquorice_commandline_tool.html#usage-parameters-and-examples">Usage, Parameters, and Examples</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">LIQUORICE</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>liquorice.utils.BiasModel</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for liquorice.utils.BiasModel</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_hist_gradient_boosting</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">HistGradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span><span class="p">,</span><span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">dump</span><span class="p">,</span><span class="n">load</span><span class="p">,</span><span class="n">parallel_backend</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">typing</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span><span class="n">Union</span>
<span class="kn">import</span> <span class="nn">typing_extensions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<div class="viewcode-block" id="SklearnStyleRegressor"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.SklearnStyleRegressor">[docs]</a><span class="k">class</span> <span class="nc">SklearnStyleRegressor</span><span class="p">(</span><span class="n">typing_extensions</span><span class="o">.</span><span class="n">Protocol</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Introduced here for typing purposes only.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="SklearnStyleRegressor.fit"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.SklearnStyleRegressor.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> <span class="o">...</span></div>
<div class="viewcode-block" id="SklearnStyleRegressor.predict"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.SklearnStyleRegressor.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span> <span class="o">...</span></div>
<div class="viewcode-block" id="SklearnStyleRegressor.score"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.SklearnStyleRegressor.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> <span class="o">...</span></div>
<div class="viewcode-block" id="SklearnStyleRegressor.set_params"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.SklearnStyleRegressor.set_params">[docs]</a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span> <span class="o">...</span></div></div>


<div class="viewcode-block" id="BiasModel"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.BiasModel">[docs]</a><span class="k">class</span> <span class="nc">BiasModel</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An object that can be used to train a machine learning model that predicts coverage based on bias</span>
<span class="sd">    factors. The performance of the trained model can be tested, and it can be used to correct coverage values</span>
<span class="sd">    by regressing out the influence of the bias factors.</span>

<span class="sd">    :param training_df: `pandas.DataFrame` used for training (and optionally for performance assessment) of the</span>
<span class="sd">        model. Must contain the column *coverage* and all columns specified under **features**. Can be None if</span>
<span class="sd">        :func:`train_biasmodel` won&#39;t be called. Ignored in :func`train_biasmodel_2fold_CV_and_predict`.</span>
<span class="sd">    :param df_to_correct: `pandas.DataFrame` for which coverage should be corrected by the trained model. Must</span>
<span class="sd">        contain the column *coverage* and all columns specified under **features**. Can be None if</span>
<span class="sd">        :func:`get_table_with_corrected_coverage_using_trained_biasmodel` won&#39;t be called.</span>
<span class="sd">    :param biasmodel_path: Path to which the trained biasmodel should be saved to and/or loaded from. Must be a</span>
<span class="sd">        .joblib file. Can be None if :func:`get_table_with_corrected_coverage_using_trained_biasmodel` won&#39;t be</span>
<span class="sd">        called, in that case, no biasmodel will be saved.</span>
<span class="sd">    :param features: A list of bias factors that should be used as features for the machine learning model. Default</span>
<span class="sd">        &quot;all&quot; sets all bias-factors as features: forward,reverse, and max mappability, di/trinucleotide factors and</span>
<span class="sd">        GC-content. Bin size is not included by default, it can be added as a feature via `use_binsize_as_feature`.</span>
<span class="sd">    :param nr_of_bins_for_training_and_testing: Subset the training_df to this many bins. Can speed up the</span>
<span class="sd">        computation time, but using too few bins will make the model less precise. Can be None, then all bins will be</span>
<span class="sd">        used.</span>
<span class="sd">    :param sklearn_model: A regressor that implements to functions .fit() and .predict() (e.g. from `sklearn`).</span>
<span class="sd">        Default of None means using sklearn.ensemble.RandomForestRegressor with prior standard-scaling, and with</span>
<span class="sd">        default settings.</span>
<span class="sd">    :param n_jobs: How many jobs to run in parallel when training the model</span>
<span class="sd">    :param filename_performance_metrics: If **test_fraction** or **cross_validate_k** is set, save a .csv containing</span>
<span class="sd">        the performance metrics (r2, MSE) to this path.</span>
<span class="sd">    :param filename_feature_importances: If set, save a .csv file containing the feature importances inferred from</span>
<span class="sd">        the trained model to this path.</span>
<span class="sd">    :param use_binsize_as_feature: If True, include &quot;bin size&quot; as a feature for the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># :param test_fraction: Use this fraction of bins in training_df to test model performance. This fraction of</span>
    <span class="c1">#     bins will not be used to train the model and are only used for testing. Set to None to disable performance</span>
    <span class="c1">#     metrics for training_df (unless **cross_validate_k** is set).</span>
    <span class="c1"># :param cross_validate_k: Perform a k-fold cross-validation instead of a simple train/test split to evaluate</span>
    <span class="c1">#     model performance. The saved model will be trained on the full dataset.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_df</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">df_to_correct</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span>
                 <span class="n">biasmodel_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;trained_biasmodel.joblib&quot;</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
                 <span class="n">nr_of_bins_for_training_and_testing</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
                 <span class="n">sklearn_model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="n">SklearnStyleRegressor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="c1">#test_fraction: Union[None, float] = None, cross_validate_k: Union[None, int] = None,</span>
                 <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">filename_performance_metrics</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;biasmodel_performance_metrics.csv&quot;</span><span class="p">,</span>
                 <span class="n">filename_feature_importances</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1">#&quot;biasmodel_feature_importances.csv&quot;</span>
                 <span class="n">use_binsize_as_feature</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>


        <span class="k">if</span> <span class="n">training_df</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">df_to_correct</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;training_df and df_to_correct cannot both be None.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">=</span><span class="n">training_df</span>
        <span class="k">if</span> <span class="n">training_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nr_rows_with_na</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">nr_rows_with_na</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training dataset contained </span><span class="si">{</span><span class="n">nr_rows_with_na</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> rows with&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot; empty values, these were discarded.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">=</span><span class="n">df_to_correct</span>
        <span class="k">if</span> <span class="n">df_to_correct</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nr_rows_with_na</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">nr_rows_with_na</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset that should be corrected contained &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">nr_rows_with_na</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot; rows with empty values, these were discarded.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span><span class="o">=</span><span class="n">biasmodel_path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.joblib&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;biasmodel_path must have a .joblib extension.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">=</span><span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_binsize_as_feature</span><span class="o">=</span><span class="n">use_binsize_as_feature</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span><span class="o">==</span><span class="nb">str</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">==</span><span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="n">df_for_feature_extraction</span><span class="o">=</span><span class="n">training_df</span> <span class="k">if</span> <span class="n">training_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">df_to_correct</span>
            <span class="n">drop_from_features</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;chromosome&quot;</span><span class="p">,</span><span class="s2">&quot;start&quot;</span><span class="p">,</span><span class="s2">&quot;end&quot;</span><span class="p">,</span><span class="s2">&quot;bin nr.&quot;</span><span class="p">,</span><span class="s2">&quot;sequence&quot;</span><span class="p">,</span><span class="s2">&quot;mappability&quot;</span><span class="p">,</span><span class="s2">&quot;coverage&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;CNA-uncorrected coverage&quot;</span><span class="p">,</span><span class="s2">&quot;corrected coverage&quot;</span><span class="p">]</span><span class="o">+</span>\
                               <span class="p">([</span><span class="s2">&quot;bin size&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_binsize_as_feature</span> <span class="k">else</span> <span class="p">[])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_for_feature_extraction</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">drop_from_features</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span><span class="o">==</span><span class="nb">list</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Please specify either the string &#39;all&#39; or a list of features as parameter &#39;features&#39;.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nr_of_bins_for_training_and_testing</span><span class="o">=</span><span class="n">nr_of_bins_for_training_and_testing</span>
        <span class="c1"># self.test_fraction=test_fraction</span>
        <span class="c1"># self.cross_validate_k=cross_validate_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename_performance_metrics</span><span class="o">=</span><span class="n">filename_performance_metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename_feature_importances</span><span class="o">=</span><span class="n">filename_feature_importances</span>

        <span class="k">if</span> <span class="n">sklearn_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">=</span><span class="n">HistGradientBoostingRegressor</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">54</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">=</span><span class="n">sklearn_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;coverage&quot;</span>


<div class="viewcode-block" id="BiasModel.train_biasmodel"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.BiasModel.train_biasmodel">[docs]</a>    <span class="k">def</span> <span class="nf">train_biasmodel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train a machine learning model that predicts the values of the &#39;coverage&#39; column based on the given features. If</span>
<span class="sd">        :attr:`.test_fraction` is set, this fraction of the :attr:`.training_df` is set aside to evaluate R^2 and MSE</span>
<span class="sd">        of the model. Prior to training and a potential train/test split, the :attr:`.training_df` is subsetted to</span>
<span class="sd">        :attr:`nr_of_bins_for_training_and_testing` if it is not *None*. Writes writes a *.joblib*</span>
<span class="sd">        file containing the biasmodel to :attr:`.biasmodel_path` (unless it is `None`)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training a bias model ...&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using features: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_df</span><span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_of_bins_for_training_and_testing</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nr_of_bins_for_training_and_testing</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_of_bins_for_training_and_testing</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="c1"># if self.test_fraction:</span>
        <span class="c1">#     test_df=df.iloc[:int(df.shape[0]*self.test_fraction)]</span>
        <span class="c1">#     training_df=df.iloc[int(df.shape[0]*self.test_fraction):]</span>
        <span class="c1"># else:</span>
        <span class="c1">#     training_df=df</span>
        <span class="n">training_df</span><span class="o">=</span><span class="n">df</span>

        <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="s1">&#39;threading&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span><span class="mi">10</span><span class="p">])):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">],</span><span class="n">training_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span><span class="p">)</span>

        <span class="c1"># if self.cross_validate_k:</span>
        <span class="c1">#     scores = cross_validate(estimator=self.sklearn_model,</span>
        <span class="c1">#                             X=training_df[self.features],</span>
        <span class="c1">#                             y=training_df[self.y],</span>
        <span class="c1">#                             scoring=[&quot;r2&quot;,&quot;neg_mean_squared_error&quot;],</span>
        <span class="c1">#                             cv=self.cross_validate_k,</span>
        <span class="c1">#                             n_jobs=self.n_jobs)</span>
        <span class="c1">#     if self.filename_performance_metrics:</span>
        <span class="c1">#         score_df=pd.DataFrame({&quot;r2&quot;:scores[&quot;test_r2&quot;],&quot;MSE&quot;:-scores[&quot;test_neg_mean_squared_error&quot;]})[[</span>
        <span class="c1">#             &quot;r2&quot;,&quot;MSE&quot;]].transpose()</span>
        <span class="c1">#         score_df[&quot;mean&quot;]=score_df.mean(axis=1)</span>
        <span class="c1">#         score_df[&quot;median&quot;]=score_df.median(axis=1)</span>
        <span class="c1">#         score_df[&quot;std&quot;]=score_df.std(axis=1)</span>
        <span class="c1">#         score_df[&quot;n bins training&quot;]=int(training_df.shape[0]*(1-1/self.cross_validate_k))</span>
        <span class="c1">#         score_df.columns=[&quot;fold &quot;+str(k) for k in range(self.cross_validate_k)]+\</span>
        <span class="c1">#                          list(score_df.columns[self.cross_validate_k:])</span>
        <span class="c1">#         score_df.to_csv(self.filename_performance_metrics)</span>
        <span class="c1">#</span>
        <span class="c1"># if self.test_fraction:</span>
        <span class="c1">#     y_pred=self.sklearn_model.predict(test_df[self.features])</span>
        <span class="c1">#     y_true=test_df[self.y]</span>
        <span class="c1">#</span>
        <span class="c1">#     r2=r2_score(y_true,y_pred)</span>
        <span class="c1">#     logging.info(f&quot;R^2 for test dataset: {r2}&quot;)</span>
        <span class="c1">#     mse=mean_squared_error(y_true,y_pred)</span>
        <span class="c1">#     logging.info(f&quot;MSE for test dataset: {mse}&quot;)</span>
        <span class="c1">#     if self.filename_performance_metrics:</span>
        <span class="c1">#         with open(self.filename_performance_metrics, &quot;w&quot;) as outfile:</span>
        <span class="c1">#             print(f&quot;r2,MSE\n{r2},{mse}&quot;,end=&quot;&quot;,file=outfile)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename_feature_importances</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">feature_importances</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">key</span><span class="p">:</span><span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">feature_importances</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;Feature importance&quot;</span>
                <span class="n">feature_importances</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename_feature_importances</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span> <span class="c1"># input may be a pipeline - try this</span>
                    <span class="n">feature_importances</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">key</span><span class="p">:</span><span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">feature_importances</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;Feature importance&quot;</span>
                    <span class="n">feature_importances</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename_feature_importances</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Feature importance file could not be written. Maybe the passed model has no &quot;</span>
                                    <span class="s2">&quot;attribute &#39;.feature_importances_&#39;?&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BiasModel.get_table_with_corrected_coverage_using_trained_biasmodel"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.BiasModel.get_table_with_corrected_coverage_using_trained_biasmodel">[docs]</a>    <span class="k">def</span> <span class="nf">get_table_with_corrected_coverage_using_trained_biasmodel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts coverage based on :attr:`.features` in the DataFrame :attr:`df_to_correct` and the biasmodel</span>
<span class="sd">        under :attr:`.biasmodel_path`. Subtracts this prediction from the observed coverage to regress out the effect</span>
<span class="sd">        of the bias-factors (i.e. :attr:`.features`) on the coverage.</span>
<span class="sd">        </span>
<span class="sd">        :return: Returns :attr:`df_to_correct` with an additional column &quot;corrected coverage&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correcting using trained bias model ...&quot;</span><span class="p">)</span>

        <span class="n">trained_model</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biasmodel_path</span><span class="p">)</span>
        <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">trained_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="n">y_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_pred</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="s2">&quot;corrected coverage&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">y_corr</span>

        <span class="n">r2</span><span class="o">=</span><span class="n">r2_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R^2 for dataset to be corrected: </span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">mse</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE for dataset to be corrected: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename_performance_metrics</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename_performance_metrics</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outf</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R^2</span><span class="se">\t</span><span class="s2">MSE&quot;</span><span class="p">,</span><span class="n">file</span><span class="o">=</span><span class="n">outf</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">file</span><span class="o">=</span><span class="n">outf</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span></div>


<div class="viewcode-block" id="BiasModel.train_biasmodel_2fold_CV_and_predict"><a class="viewcode-back" href="../../../liquorice.html#liquorice.utils.BiasModel.BiasModel.train_biasmodel_2fold_CV_and_predict">[docs]</a>    <span class="k">def</span> <span class="nf">train_biasmodel_2fold_CV_and_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">exclude_these_bin_nrs</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span><span class="p">[])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train a machine learning model that predicts the values of the &#39;coverage&#39; column based on the given features.</span>
<span class="sd">        Will use each half of the :attr:`df_to_correct` to train the model for predictions of the other half.</span>
<span class="sd">        Ignores :attr:`nr_of_bins_for_training_and_testing`, :attr:`cross_validate_k` and writes returns the performance</span>
<span class="sd">         metrics and returns the dataframe with predictions.</span>
<span class="sd">         Important: does not use :attr`training_df`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using CVs to train bisamodel and predict...&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Excluding from training the following bins: </span><span class="si">{</span><span class="n">exclude_these_bin_nrs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using features: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">df_first_half</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">)]</span>
        <span class="n">train_df_first_half</span><span class="o">=</span><span class="n">df_first_half</span><span class="p">[</span><span class="o">~</span> <span class="n">df_first_half</span><span class="p">[</span><span class="s2">&quot;bin nr.&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">exclude_these_bin_nrs</span><span class="p">)]</span>
        <span class="n">df_second_half</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">):]</span>
        <span class="n">train_df_second_half</span><span class="o">=</span><span class="n">df_second_half</span><span class="p">[</span><span class="o">~</span> <span class="n">df_second_half</span><span class="p">[</span><span class="s2">&quot;bin nr.&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">exclude_these_bin_nrs</span><span class="p">)]</span>

        <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="s1">&#39;threading&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">])):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">],</span> <span class="n">train_df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">])</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">])</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training-set R^2 for the first cross validation fold: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">]))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Out-of-sample R^2 for the first cross validation fold: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="s1">&#39;threading&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="nb">min</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">])):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">],</span> <span class="n">train_df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">])</span>
        <span class="n">y_pred_second_half</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">])</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training-set R^2 for the second cross validation fold: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_first_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">]))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Out-of-sample R^2 for the second cross validation fold: </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">df_second_half</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred_second_half</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">y_pred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="n">y_pred_second_half</span><span class="p">)</span>

        <span class="n">y_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="s2">&quot;corrected coverage&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">y_corr</span>

        <span class="n">r2</span><span class="o">=</span><span class="n">r2_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cross-validated R^2 overall: </span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">mse</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cross-validated MSE overall: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename_performance_metrics</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename_performance_metrics</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outf</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R^2</span><span class="se">\t</span><span class="s2">MSE&quot;</span><span class="p">,</span><span class="n">file</span><span class="o">=</span><span class="n">outf</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">file</span><span class="o">=</span><span class="n">outf</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_to_correct</span></div></div>

</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Peter Peneder.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>